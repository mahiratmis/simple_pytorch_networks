{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('p37': conda)",
   "metadata": {
    "interpreter": {
     "hash": "ab66cd2a7eef53324163067b08cf46878006a1ba8ec8ccae931ca78a06f8215e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# SLP in Pytorch\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Import Necessary modules"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision                                 # datasets and transformations modules\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn                              # neural network module\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim                        # optimization module\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.tensorboard import SummaryWriter  # logging module\n",
    "from torchvision.utils import make_grid, save_image"
   ]
  },
  {
   "source": [
    "## 1.Define the Network"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All networks derive from the base class nn.Module\n",
    "class Perceptron(nn.Module):\n",
    "    # get input and output dimensions as input\n",
    "    def __init__(self, d, K, H=None):\n",
    "        # all derived classes must call __init__ method of super class\n",
    "        super(Perceptron, self).__init__()\n",
    "        if H is None:\n",
    "            # create a fully connected layer from input to output\n",
    "            self.model = nn.Linear(d, K)\n",
    "        else:\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Linear(d,H),\n",
    "                nn.Sigmoid(),\n",
    "                nn.Linear(H,K)\n",
    "            )\n",
    "    \n",
    "    # forward method should get the input and return the output\n",
    "    def forward(self,x):\n",
    "        batch_size = x.shape[0]\n",
    "        # flatten the image from BxCxHXW to Bx784\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = self.model(x)\n",
    "        # softmax is internally done inside cross entropy loss\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "source": [
    "## 2.Define parameters and hyper-parameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch parameters\n",
    "SEED = 60            # reproducability\n",
    "# NN Parameters\n",
    "EPOCHS = 20          # number of epochs\n",
    "LR = 0.01            # learning rate\n",
    "MOMENTUM = 0.9       # momentum for the optimizer\n",
    "WEIGHT_DECAY = 1e-5  # weight decay for the optimizer\n",
    "GAMMA = 0.1          # learning rate schedular\n",
    "BATCH_SIZE = 64      # number of images to load per iteration\n",
    "d = 784              # number of input features \n",
    "K = 10               # number of output features\n",
    "H = None             # if H is none SLP else MLP\n"
   ]
  },
  {
   "source": [
    "# 3.Assure reproducability"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb8fc031370>"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "# manual seed to reproduce same results\n",
    "torch.manual_seed(SEED)\n"
   ]
  },
  {
   "source": [
    "# 4.Define datasets and  dataloaders"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DOWNLOADING AND LOADING MNIST DATASET \n",
    "mnist_folder= './data'\n",
    "\n",
    "# download the dataset if not already downloaded and set necessery transforms\n",
    "tr_dataset   = datasets.MNIST(mnist_folder, train=True, download=True, transform=transforms.ToTensor())\n",
    "# prepare loader for the training dataset\n",
    "train_loader = torch.utils.data.DataLoader(tr_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8)\n",
    "\n",
    "# download the dataset if not already downloaded and set necessery transforms\n",
    "test_dataset = datasets.MNIST(mnist_folder, train=False, download=True, transform=transforms.ToTensor())\n",
    "# prepare loader for the test dataset\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=8)\n"
   ]
  },
  {
   "source": [
    "## 5.Create a network instance and move it to the device you want to run computations on"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "model.weight torch.Size([10, 784])\nmodel.bias torch.Size([10])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Perceptron(\n",
       "  (model): Linear(in_features=784, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "# create the network\n",
    "net = Perceptron(d,K,H)\n",
    "\n",
    "# print network parameter names and their size\n",
    "for name, param in net.named_parameters():\n",
    "  print(name, param.size())\n",
    "\n",
    "# check if CUDA is available\n",
    "cuda = torch.cuda.is_available()  \n",
    "device = torch.device(\"cuda:0\" if cuda else \"cpu\")\n",
    "\n",
    "# if cuda is available move network into gpu\n",
    "net.to(device)\n"
   ]
  },
  {
   "source": [
    "## 6.Specify the loss function and the optimizer"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the loss to be used\n",
    "# softmax is internally computed.\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "# specify the optimizer to update the weights during backward pass\n",
    "optimizer = optim.SGD(net.parameters(), lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "# change learning rate over time\n",
    "scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=GAMMA)\n"
   ]
  },
  {
   "source": [
    "## 7. Define training function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net():\n",
    "  # put the network in training mode\n",
    "  net.train()\n",
    "  # keep record of the loss value\n",
    "  epoch_loss = 0.0\n",
    "  # use training data as batches\n",
    "  for xt, rt in train_loader:\n",
    "    # move training instances and corresponding labels into gpu if cuda is available\n",
    "    xt, rt = xt.to(device), rt.to(device)\n",
    "    # clear the previously accumulated gradients\n",
    "    optimizer.zero_grad()\n",
    "    # forward the network\n",
    "    yt = net(xt)\n",
    "    # calculate loss\n",
    "    loss = loss_fn(yt, rt)\n",
    "    # make a backward pass, calculate gradients\n",
    "    loss.backward()\n",
    "    # update weights\n",
    "    optimizer.step()\n",
    "    # accumulate loss\n",
    "    epoch_loss += loss.item()\n",
    "  return epoch_loss\n",
    "  "
   ]
  },
  {
   "source": [
    "## 8. Define test function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_net(loader):\n",
    "  # put the network in evaluation mode\n",
    "  net.eval()\n",
    "  # keep record of the loss value\n",
    "  total_loss = 0.0\n",
    "  # number of correctly classified instances\n",
    "  correct = 0\n",
    "  # disable gradient tracking\n",
    "  with torch.no_grad():\n",
    "    for xt, rt in loader:\n",
    "      # move training instances and corresponding labels into gpu if cuda is available\n",
    "      xt, rt = xt.to(device), rt.to(device)\n",
    "      # forward the network\n",
    "      yt = net(xt)\n",
    "      # calculate loss\n",
    "      loss = loss_fn(yt, rt)\n",
    "      # accumulate loss\n",
    "      total_loss += loss.item()\n",
    "      # get predicted classes\n",
    "      pred = yt.argmax(dim=1)\n",
    "      # accumulate correctly classified image counts\n",
    "      correct += (pred == rt).sum().item()\n",
    "      #correct += pred.eq(rt.view_as(pred)).sum().item()\n",
    "  return correct/len(loader.dataset), total_loss \n",
    "  "
   ]
  },
  {
   "source": [
    "## 9.Train the network"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the logger instance\n",
    "# by default creates run directory inside current folder\n",
    "writer = SummaryWriter()           \n",
    "# train the network\n",
    "for epoch in range(1,EPOCHS+1):\n",
    "  # train network for one epoch\n",
    "  train_net()\n",
    "  # get accuracy and loss on the training dataset\n",
    "  tr_ac, tr_loss = eval_net(train_loader)\n",
    "  # get accuracy and loss on the test dataset\n",
    "  tt_ac, tt_loss = eval_net(test_loader)\n",
    "  # save training stats\n",
    "  writer.add_scalar(\"Loss/train\", tr_loss, epoch)\n",
    "  writer.add_scalar(\"Accuracy/train\", tr_ac, epoch)\n",
    "  # save test stats\n",
    "  writer.add_scalar(\"Loss/test\", tt_loss, epoch)\n",
    "  writer.add_scalar(\"Accuracy/test\", tt_ac, epoch)\n",
    "  # run only if SLP\n",
    "  if H is None:\n",
    "    weights = net.model.weight                  # 10x784\n",
    "    weights = weights.view(10, 28, 28)          # 10x28x28\n",
    "    weights = weights.unsqueeze(dim=1)          # 10x1x28x28\n",
    "    mean_images = make_grid(weights, normalize=True)\n",
    "    writer.add_image(\"Images/mean_images\", mean_images, epoch)\n",
    "\n",
    "writer.flush()\n",
    "writer.close()\n"
   ]
  },
  {
   "source": [
    "## 10. Save the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the network model\n",
    "if H is None:\n",
    "    torch.save(net.state_dict(), 'perceptron_outputs/slp.pth')\n",
    "else:\n",
    "    torch.save(net.state_dict(), 'perceptron_outputs/mlp.pth')\n"
   ]
  },
  {
   "source": [
    "## 11. Visualize results on tensorboard"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n  %reload_ext tensorboard\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Reusing TensorBoard on port 6006 (pid 527), started 0:04:17 ago. (Use '!kill 527' to kill it.)"
     },
     "metadata": {}
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs\n",
    "# open http://localhost:6006/ to view the results"
   ]
  }
 ]
}