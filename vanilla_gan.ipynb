{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37264bitc1614707bae24ab18c8f392d435eabb1",
   "display_name": "Python 3.7.2 64-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid, save_image\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 784),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x.view(-1, 1, 28, 28)   # Bx1x28x28\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(784, 1024),   #784 is MNIST input feature dimension\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.Linear(256, 1),      # single value stating fake or real\n",
    "            nn.Sigmoid()            # value between 0 and 1\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)         # reshape input same as torch.flatten(x, start_dim=1)\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch parameters\n",
    "SEED = 60            # reproducability\n",
    "# NN Parameters\n",
    "EPOCHS = 50          # number of epochs\n",
    "LR = 0.001           # learning rate\n",
    "MOMENTUM = 0.9       # momentum for the optimizer\n",
    "WEIGHT_DECAY = 1e-5  # weight decay for the optimizer\n",
    "GAMMA = 0.1          # learning rate schedular\n",
    "BATCH_SIZE = 256     # number of images to load per iteration\n",
    "# GAN parameters\n",
    "SAMPLE_SIZE = 64     # number of fake images to sample\n",
    "LATENT_SIZE = 128    # size of latent or noise vector\n",
    "DISC_STEPS  = 1      # number of steps to apply to the discriminator\n",
    "\n",
    "# manual seed to reproduce same results\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# DOWNLOADING AND LOADING MNIST DATASET \n",
    "mnist_folder= '/home/atmis/Documents/DATASETS/mnist'\n",
    "\n",
    "# normalize each image and set the pixel values between -1 and 1\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "to_pil_image = transforms.ToPILImage()\n",
    "\n",
    "# download the dataset if not already downloaded and set necessery transforms\n",
    "tr_dataset   = MNIST(mnist_folder, train=True, download=True, transform=img_transform)\n",
    "# prepare loader for the training dataset\n",
    "train_loader = torch.utils.data.DataLoader(tr_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# determine where to run the code\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "# create the generator network and move to gpu if available\n",
    "gen_net = Generator(LATENT_SIZE).to(device)\n",
    "# create the discriminator and move to gpu if available\n",
    "disc_net = Discriminator().to(device)\n",
    "\n",
    "# specify the loss to be used\n",
    "# Binary Cross Entropy Loss\n",
    "loss_fn = nn.BCELoss()\n",
    "# specify the optimizer for generator network\n",
    "optimizer_gen = optim.SGD(gen_net.parameters(), lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "# specify the optimizer for discriminator network\n",
    "optimizer_disc = optim.Adam(disc_net.parameters(), lr=LR)\n",
    "\n",
    "# function to create the noise vector\n",
    "def create_noise():\n",
    "    return torch.randn(SAMPLE_SIZE, LATENT_SIZE).to(device)\n",
    "\n",
    "\n",
    "def train_discriminator(real_x, fake_x):\n",
    "    B = real_x.size(0)                         # batch size\n",
    "    real_y = torch.ones(B, 1).to(device)       # create labels of 1\n",
    "    fake_y = torch.zeros(SAMPLE_SIZE, 1).to(device)      # create labels of 0\n",
    "    \n",
    "    optimizer_disc.zero_grad()\n",
    "    # forward pass the real data\n",
    "    output_real = disc_net(real_x)\n",
    "    # estimate loss         \n",
    "    loss_real = loss_fn(output_real, real_y)\n",
    "    # forward pass the fake data\n",
    "    output_fake = disc_net(fake_x)\n",
    "    # estimate loss\n",
    "    loss_fake = loss_fn(output_fake, fake_y)\n",
    "    # accumulate gradients for both passes \n",
    "    loss_real.backward()\n",
    "    loss_fake.backward()\n",
    "    # update weights of discriminator\n",
    "    optimizer_disc.step()\n",
    "    return loss_real + loss_fake\n",
    "\n",
    "# update generator weights using the gradients of discriminator\n",
    "def train_generator(fake_x):\n",
    "    B = fake_x.size(0)                       # batch size\n",
    "    real_y = torch.ones(B, 1).to(device)     # create labels of 1\n",
    "\n",
    "    optimizer_gen.zero_grad()\n",
    "    # forward pass the fake data on discriminator\n",
    "    output = disc_net(fake_x)\n",
    "    # determine how far we are from real label\n",
    "    loss = loss_fn(output, real_y)\n",
    "    # calculate gradients\n",
    "    loss.backward()\n",
    "    # update generator weights\n",
    "    optimizer_gen.step()\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to save the images generated by the generator\n",
    "def save_generator_image(image, path):\n",
    "    save_image(image, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Target and input must have the same number of elements. target nelement (256) != input nelement (64)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-98ee88e4684e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mreal_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;31m# train the discriminator network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mloss_d\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_discriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mfake_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreate_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# train the generator network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-3aa686ebf0fd>\u001b[0m in \u001b[0;36mtrain_discriminator\u001b[0;34m(real_x, fake_x)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0moutput_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisc_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# estimate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mloss_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0;31m# accumulate gradients for both passes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mloss_real\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p37/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p37/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/p37/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2056\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2057\u001b[0m         raise ValueError(\"Target and input must have the same number of elements. target nelement ({}) \"\n\u001b[0;32m-> 2058\u001b[0;31m                          \"!= input nelement ({})\".format(target.numel(), input.numel()))\n\u001b[0m\u001b[1;32m   2059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2060\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Target and input must have the same number of elements. target nelement (256) != input nelement (64)"
     ]
    }
   ],
   "source": [
    "losses_g = [] # store generator loss after each epoch\n",
    "losses_d = [] # store discriminator loss after each epoch\n",
    "images = []   # store images generatd by the generator\n",
    "\n",
    "\n",
    "# create the noise vector\n",
    "noise = create_noise()\n",
    "# put the networks in training mode\n",
    "gen_net.train()\n",
    "disc_net.train()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    loss_g = 0.0\n",
    "    loss_d = 0.0\n",
    "    for idx, (img, _) in enumerate(train_loader):\n",
    "        # move image to gpu if exists\n",
    "        img = img.to(device)\n",
    "        # get batch size\n",
    "        b_size = len(img)\n",
    "        # run the discriminator for DISC_STEPS number of steps\n",
    "        for _ in range(DISC_STEPS):\n",
    "            fake_x = gen_net(create_noise()).detach()\n",
    "            real_x = img\n",
    "            # train the discriminator network\n",
    "            loss_d += train_discriminator(real_x, fake_x)\n",
    "        fake_x = gen_net(create_noise())\n",
    "        # train the generator network\n",
    "        loss_g += train_generator(fake_x)\n",
    "    # create the final fake image for the epoch\n",
    "    generated_img = gen_net(noise).cpu().detach()\n",
    "    # make the images as grid\n",
    "    generated_img = make_grid(generated_img)\n",
    "    # save the generated torch tensor models to disk\n",
    "    save_generator_image(generated_img, f\"gan_outputs/gen_img{epoch}.png\")\n",
    "    images.append(generated_img)\n",
    "    epoch_loss_g = loss_g / idx # total generator loss for the epoch\n",
    "    epoch_loss_d = loss_d / idx # total discriminator loss for the epoch\n",
    "    losses_g.append(epoch_loss_g)\n",
    "    losses_d.append(epoch_loss_d)\n",
    "    \n",
    "    print(f\"Epoch {epoch} of {EPOCHS}\")\n",
    "    print(f\"Generator loss: {epoch_loss_g:.8f}, Discriminator loss: {epoch_loss_d:.8f}\")\n",
    "\n",
    "print('DONE TRAINING')\n",
    "torch.save(gen_net.state_dict(), 'gan_outputs/generator.pth')\n",
    "torch.save(disc_net.state_dict(), 'gan_outputs/discriminator.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}